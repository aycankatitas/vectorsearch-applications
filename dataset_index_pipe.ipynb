{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FOR COLAB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import GitHub branch\n",
        "!git clone -b chunk https://github.com/aycankatitas/vectorsearch-applications.git\n",
        "%cd /content/vectorsearch-applications\n",
        "# Unzip finetuned models \n",
        "!unzip /content/vectorsearch-applications/models\n",
        "# Enable third-party widgets\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Creation, Indexing and Reranking Pipeline\n",
        "\n",
        "This code is created to support a pipeline for original or finetuned transformers embedding models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Zyz95nTM5MP5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "load_dotenv(find_dotenv(), override=True)\n",
        "\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "from typing import List\n",
        "from math import ceil\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from rich import print\n",
        "from torch import cuda\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Dataset Creation and Indexing\n",
        "from preprocessing import FileIO\n",
        "import tiktoken\n",
        "from llama_index.text_splitter import SentenceSplitter\n",
        "from sentence_transformers import CrossEncoder,SentenceTransformer\n",
        "from weaviate_interface import WeaviateClient, WeaviateIndexer\n",
        "from class_templates import impact_theory_class_properties\n",
        "from pipeline import split_contents, encode_content_splits, join_metadata, create_dataset, retrieval_evaluation\n",
        "\n",
        "# Retrieval Evaluation\n",
        "from retrieval_evaluation import calc_hit_rate_scores, calc_mrr_scores, record_results, add_params, execute_evaluation\n",
        "from llama_index.finetuning import EmbeddingQAFinetuneDataset\n",
        "from weaviate_interface import WeaviateClient\n",
        "from getpass import getpass\n",
        "import openai\n",
        "\n",
        "# ReRanker\n",
        "from reranker import ReRanker"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_XUkMonS0th"
      },
      "source": [
        "## Set Constants\n",
        "\n",
        "For Open Source Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "cRWmn0w5S6Jj"
      },
      "outputs": [],
      "source": [
        "# don't change to compare to golden dataset\n",
        "chunk_size = 256\n",
        "\n",
        "#tokenizer - don't change to compare to golden dataset\n",
        "encoding = tiktoken.encoding_for_model('gpt-3.5-turbo')\n",
        "#text splitter - don't change to compare to golden dataset\n",
        "splitter = SentenceSplitter(chunk_overlap=0, chunk_size=chunk_size,tokenizer=encoding.encode)\n",
        "\n",
        "#model\n",
        "#model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
        "model_name = \"models/finetuned-all-MiniLM-L6-v2-300\"\n",
        "model = SentenceTransformer(model_name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaLj5b67BqgC"
      },
      "source": [
        "## Set Dataset Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "id": "wz0vzWQYOjOK",
        "outputId": "ef3295ab-a1cc-44be-88d5-e5269ac68490"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">.<span style=\"color: #800080; text-decoration-color: #800080\">/data/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">impact-theory_finetuned-all-MiniLM-L6-v2-300_1216</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              ".\u001b[35m/data/\u001b[0m\u001b[95mimpact-theory_finetuned-all-MiniLM-L6-v2-300_1216\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Define file name outpath\n",
        "data_path = \"./data/\"\n",
        "date = \"1216\"\n",
        "model_name_short = model_name.split(\"/\")[1]\n",
        "outpath = data_path+\"impact-theory\" + \"_\" + model_name_short + \"_\" + date\n",
        "print(outpath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WIbijBas5S9"
      },
      "source": [
        "## Configure Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPcNMszQBflP"
      },
      "outputs": [],
      "source": [
        "class_name = \"Impact_theory_finetunedminiLM_reranker_256\"\n",
        "\n",
        "ef = 64\n",
        "efConstruction = 128\n",
        "maxConnection = 32\n",
        "\n",
        "class_config = {'classes': [\n",
        "\n",
        "                      {\"class\": class_name,\n",
        "\n",
        "                       \"description\": \"Episodes of Impact Theory up to Nov 2023\",\n",
        "\n",
        "                       \"vectorIndexType\": \"hnsw\",\n",
        "\n",
        "                       # Vector index specific settings\n",
        "                       \"vectorIndexConfig\": {\n",
        "\n",
        "                            \"ef\": ef,\n",
        "                            \"efConstruction\": efConstruction,\n",
        "                            \"maxConnections\": maxConnection,\n",
        "                                            },\n",
        "\n",
        "                       \"vectorizer\": \"none\",\n",
        "\n",
        "                       # pre-defined property mappings\n",
        "                       \"properties\": impact_theory_class_properties}\n",
        "                      ]\n",
        "               }\n",
        "\n",
        "print(class_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dy8BVFFzBzKH"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "7ckoLrUZB1XZ"
      },
      "outputs": [],
      "source": [
        "#corpus\n",
        "data=FileIO().load_json(\"data/impact_theory_data.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhbqVpnqBefV"
      },
      "source": [
        "## Create Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "NoEYqAbB23Wg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating dataset using chunk_size: 256\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e822747127d4c809fb4e89bf9f0b950",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/384 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[37], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create dataset\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m docs \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_outpath_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutpath\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/Git/vectorsearch-applications/pipeline.py:42\u001b[0m, in \u001b[0;36mcreate_dataset\u001b[0;34m(corpus, embedding_model, text_splitter, file_outpath_prefix, content_field, embedding_field, device)\u001b[0m\n\u001b[1;32m     38\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Split Corpus\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m content_splits \u001b[38;5;241m=\u001b[39m \u001b[43msplit_contents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtext_splitter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Vector Embeddings\u001b[39;00m\n\u001b[1;32m     45\u001b[0m text_vector_tuples \u001b[38;5;241m=\u001b[39m encode_content_splits(content_splits, embedding_model,device)\n",
            "File \u001b[0;32m~/Desktop/Git/vectorsearch-applications/pipeline.py:83\u001b[0m, in \u001b[0;36msplit_contents\u001b[0;34m(corpus, text_splitter, content_field)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit_contents\u001b[39m(corpus: List[\u001b[38;5;28mdict\u001b[39m],\n\u001b[1;32m     58\u001b[0m                    text_splitter: SentenceSplitter,\n\u001b[1;32m     59\u001b[0m                    content_field: \u001b[38;5;28mstr\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     60\u001b[0m                    ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[List[\u001b[38;5;28mstr\u001b[39m]]:\n\u001b[1;32m     61\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;124;03m    Given a corpus of \"documents\" with text content, this function splits the\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;03m    content field into chunks sizes as specified by the text_splitter.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;124;03m                ]\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m---> 83\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m [text_splitter\u001b[38;5;241m.\u001b[39msplit_text(episode[content_field]) \u001b[38;5;28;01mfor\u001b[39;00m episode \u001b[38;5;129;01min\u001b[39;00m tqdm(corpus)]\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m chunks\n",
            "File \u001b[0;32m~/Desktop/Git/vectorsearch-applications/pipeline.py:83\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit_contents\u001b[39m(corpus: List[\u001b[38;5;28mdict\u001b[39m],\n\u001b[1;32m     58\u001b[0m                    text_splitter: SentenceSplitter,\n\u001b[1;32m     59\u001b[0m                    content_field: \u001b[38;5;28mstr\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     60\u001b[0m                    ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[List[\u001b[38;5;28mstr\u001b[39m]]:\n\u001b[1;32m     61\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;124;03m    Given a corpus of \"documents\" with text content, this function splits the\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;03m    content field into chunks sizes as specified by the text_splitter.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;124;03m                ]\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m---> 83\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m [\u001b[43mtext_splitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepisode\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcontent_field\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m episode \u001b[38;5;129;01min\u001b[39;00m tqdm(corpus)]\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m chunks\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/impactenv/lib/python3.10/site-packages/llama_index/node_parser/text/sentence.py:164\u001b[0m, in \u001b[0;36mSentenceSplitter.split_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_split_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/impactenv/lib/python3.10/site-packages/llama_index/node_parser/text/sentence.py:178\u001b[0m, in \u001b[0;36mSentenceSplitter._split_text\u001b[0;34m(self, text, chunk_size)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [text]\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[1;32m    176\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mCHUNKING, payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mCHUNKS: [text]}\n\u001b[1;32m    177\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m event:\n\u001b[0;32m--> 178\u001b[0m     splits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge(splits, chunk_size)\n\u001b[1;32m    181\u001b[0m     event\u001b[38;5;241m.\u001b[39mon_end(payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mCHUNKS: chunks})\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/impactenv/lib/python3.10/site-packages/llama_index/node_parser/text/sentence.py:198\u001b[0m, in \u001b[0;36mSentenceSplitter._split\u001b[0;34m(self, text, chunk_size)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_token_size(text) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m chunk_size:\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [_Split(text, is_sentence\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)]\n\u001b[0;32m--> 198\u001b[0m text_splits_by_fns, is_sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_splits_by_fns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m text_splits \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text_split_by_fns \u001b[38;5;129;01min\u001b[39;00m text_splits_by_fns:\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/impactenv/lib/python3.10/site-packages/llama_index/node_parser/text/sentence.py:293\u001b[0m, in \u001b[0;36mSentenceSplitter._get_splits_by_fns\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_splits_by_fns\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mbool\u001b[39m]:\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m split_fn \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_fns:\n\u001b[0;32m--> 293\u001b[0m         splits \u001b[38;5;241m=\u001b[39m \u001b[43msplit_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(splits) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    295\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m splits, \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/impactenv/lib/python3.10/site-packages/llama_index/node_parser/text/utils.py:69\u001b[0m, in \u001b[0;36msplit_by_sentence_tokenizer.<locals>.split\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit\u001b[39m(text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m---> 69\u001b[0m     spans \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspan_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, span \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(spans):\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/impactenv/lib/python3.10/site-packages/nltk/tokenize/punkt.py:1329\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer.span_tokenize\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m realign_boundaries:\n\u001b[1;32m   1328\u001b[0m     slices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_realign_boundaries(text, slices)\n\u001b[0;32m-> 1329\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m slices:\n\u001b[1;32m   1330\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m (sentence\u001b[38;5;241m.\u001b[39mstart, sentence\u001b[38;5;241m.\u001b[39mstop)\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/impactenv/lib/python3.10/site-packages/nltk/tokenize/punkt.py:1459\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer._realign_boundaries\u001b[0;34m(self, text, slices)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;124;03mAttempts to realign punctuation that falls after the period but\u001b[39;00m\n\u001b[1;32m   1448\u001b[0m \u001b[38;5;124;03mshould otherwise be included in the same sentence.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;124;03m    [\"(Sent1.)\", \"Sent2.\"].\u001b[39;00m\n\u001b[1;32m   1457\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1458\u001b[0m realign \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1459\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence1, sentence2 \u001b[38;5;129;01min\u001b[39;00m _pair_iter(slices):\n\u001b[1;32m   1460\u001b[0m     sentence1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(sentence1\u001b[38;5;241m.\u001b[39mstart \u001b[38;5;241m+\u001b[39m realign, sentence1\u001b[38;5;241m.\u001b[39mstop)\n\u001b[1;32m   1461\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sentence2:\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/impactenv/lib/python3.10/site-packages/nltk/tokenize/punkt.py:324\u001b[0m, in \u001b[0;36m_pair_iter\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m (prev, el)\n\u001b[1;32m    326\u001b[0m     prev \u001b[38;5;241m=\u001b[39m el\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/impactenv/lib/python3.10/site-packages/nltk/tokenize/punkt.py:1432\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer._slices_from_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m   1430\u001b[0m last_break \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1431\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m match, context \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match_potential_end_contexts(text):\n\u001b[0;32m-> 1432\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext_contains_sentbreak\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1433\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mslice\u001b[39m(last_break, match\u001b[38;5;241m.\u001b[39mend())\n\u001b[1;32m   1434\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnext_tok\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1435\u001b[0m             \u001b[38;5;66;03m# next sentence starts after whitespace\u001b[39;00m\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/impactenv/lib/python3.10/site-packages/nltk/tokenize/punkt.py:1480\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer.text_contains_sentbreak\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m   1476\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1477\u001b[0m \u001b[38;5;124;03mReturns True if the given text includes a sentence break.\u001b[39;00m\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1479\u001b[0m found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# used to ignore last token\u001b[39;00m\n\u001b[0;32m-> 1480\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tok \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_annotate_tokens(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenize_words(text)):\n\u001b[1;32m   1481\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m found:\n\u001b[1;32m   1482\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/impactenv/lib/python3.10/site-packages/nltk/tokenize/punkt.py:1622\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer._annotate_second_pass\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m   1614\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_annotate_second_pass\u001b[39m(\n\u001b[1;32m   1615\u001b[0m     \u001b[38;5;28mself\u001b[39m, tokens: Iterator[PunktToken]\n\u001b[1;32m   1616\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[PunktToken]:\n\u001b[1;32m   1617\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1618\u001b[0m \u001b[38;5;124;03m    Performs a token-based classification (section 4) over the given\u001b[39;00m\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;124;03m    tokens, making use of the orthographic heuristic (4.1.1), collocation\u001b[39;00m\n\u001b[1;32m   1620\u001b[0m \u001b[38;5;124;03m    heuristic (4.1.2) and frequent sentence starter heuristic (4.1.3).\u001b[39;00m\n\u001b[1;32m   1621\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1622\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m token1, token2 \u001b[38;5;129;01min\u001b[39;00m _pair_iter(tokens):\n\u001b[1;32m   1623\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_second_pass_annotation(token1, token2)\n\u001b[1;32m   1624\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m token1\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/impactenv/lib/python3.10/site-packages/nltk/tokenize/punkt.py:321\u001b[0m, in \u001b[0;36m_pair_iter\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    319\u001b[0m iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(iterator)\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 321\u001b[0m     prev \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/impactenv/lib/python3.10/site-packages/nltk/tokenize/punkt.py:603\u001b[0m, in \u001b[0;36mPunktBaseClass._annotate_first_pass\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_annotate_first_pass\u001b[39m(\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;28mself\u001b[39m, tokens: Iterator[PunktToken]\n\u001b[1;32m    586\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[PunktToken]:\n\u001b[1;32m    587\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;124;03m    Perform the first pass of annotation, which makes decisions\u001b[39;00m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;124;03m    based purely based on the word type of each word:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;124;03m      - ellipsis_toks: The indices of all ellipsis marks.\u001b[39;00m\n\u001b[1;32m    602\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 603\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m aug_tok \u001b[38;5;129;01min\u001b[39;00m tokens:\n\u001b[1;32m    604\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_first_pass_annotation(aug_tok)\n\u001b[1;32m    605\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m aug_tok\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/impactenv/lib/python3.10/site-packages/nltk/tokenize/punkt.py:572\u001b[0m, in \u001b[0;36mPunktBaseClass._tokenize_words\u001b[0;34m(self, plaintext)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Token\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtok\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparastart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparastart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinestart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    573\u001b[0m parastart \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tok \u001b[38;5;129;01min\u001b[39;00m line_toks:\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/impactenv/lib/python3.10/site-packages/nltk/tokenize/punkt.py:409\u001b[0m, in \u001b[0;36mPunktToken.__init__\u001b[0;34m(self, tok, **params)\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, prop, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[0;32m--> 409\u001b[0m     \u001b[38;5;28;43msetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Create dataset\n",
        "docs = create_dataset(data, model, splitter, file_outpath_prefix=outpath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQvL-TlgCJAQ"
      },
      "source": [
        "## Load golden dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "BG5WMfmbwfuS"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Num queries in Golden Dataset: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Num queries in Golden Dataset: \u001b[1;36m100\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load golden dataset\n",
        "\n",
        "golden_dataset = EmbeddingQAFinetuneDataset.from_json(\"data/golden_100.json\")\n",
        "\n",
        "print(f'Num queries in Golden Dataset: {len(golden_dataset.queries)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDMLMhcRMlwe"
      },
      "source": [
        "## Create Weaviate Client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "-2dOs_qOMpXT"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(True, True)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "api_key = os.environ[\"WEAVIATE_API_KEY\"]\n",
        "url = os.environ[\"WEAVIATE_ENDPOINT\"]\n",
        "openai_key = os.environ[\"OPENAI_API_KEY\"]\n",
        "\n",
        "\n",
        "#instantiate client\n",
        "client = WeaviateClient(api_key,url,model_name,openai_key)\n",
        "\n",
        "#check if WCS instance is live and ready\n",
        "client.is_live(), client.is_ready()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "indexer = WeaviateIndexer(client, batch_size=200, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initiate ReRanker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "reranker_model = 'cross-encoder/ms-marco-MiniLM-L-6-v2'\n",
        "reranker = ReRanker(model_name=reranker_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvPDqQufs70g"
      },
      "source": [
        "## Load Chunked Dataset for Weaviate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "id": "RuD9WLHrOeI2",
        "outputId": "1a2f2180-6e7e-4695-d1e6-a0304976da6b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">.<span style=\"color: #800080; text-decoration-color: #800080\">/data/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">impact-theory_finetuned-all-MiniLM-L6-v2-300_1216-256.parquet</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              ".\u001b[35m/data/\u001b[0m\u001b[95mimpact-theory_finetuned-all-MiniLM-L6-v2-300_1216-256.parquet\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of data: (26448, 12)\n",
            "Memory Usage: 2.42+ MB\n"
          ]
        }
      ],
      "source": [
        "file_path = outpath + \"-\" + str(chunk_size) + \".parquet\"\n",
        "print(file_path)\n",
        "data_with_vectors = FileIO().load_parquet(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HM_OAImzQBhp"
      },
      "outputs": [],
      "source": [
        "data_with_vectors[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01WAvhghDG-E"
      },
      "source": [
        "## Show Weaviate class configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNIQ_LCStlsC"
      },
      "outputs": [],
      "source": [
        "client.schema.create(class_config)\n",
        "\n",
        "# Check mif the index is properly working\n",
        "print(client.show_class_config(class_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKI040Gzthn-"
      },
      "source": [
        "## Build Index on Weaviate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUpGVDsFt-b0",
        "outputId": "5dd02e1d-8e36-456a-e0fd-62fcd9e3651c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26448/26448 [01:36<00:00, 274.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch job completed in 1.65 minutes.\n",
            "{'class': 'Impact_theory_finetunedminiLM_256', 'name': 'qSkqqkM5B2cy', 'objectCount': 26448, 'vectorIndexingStatus': 'READY', 'vectorQueueLength': 0}\n"
          ]
        }
      ],
      "source": [
        "# Build the index\n",
        "indexer.batch_index_data(data=data_with_vectors,\n",
        "                         class_name=class_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvOw_PhfwdVH"
      },
      "source": [
        "## Retrieval Evaluation\n",
        "\n",
        "We will judge the quality of the retriever and reranker on the golden dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34,
          "referenced_widgets": [
            "704c6a1f4bdd4a60910759426f71079a",
            "f201c57fc5c146b880bcc69171df952d",
            "70675964a5694565ba01449a833dc473",
            "c6aba13165be44d0ad7335cf8a3bfad0",
            "d30eea6ca492480aadf758cacd5b6044",
            "654cee51ae9140b49354a8291121ae07",
            "ab2f1ee772954d7e8ce7e7e5bcf1af7f",
            "8c6f7af301cb4d1c9fd3b2dc46004400",
            "68f90ea90b534654bec4ecf070f182c4",
            "4554a9e328e84c0d89359b9502e3fa59",
            "1ced981f815d4a9eb2d857e44c52e8c1"
          ]
        },
        "id": "K7n8u0kdx3lr",
        "outputId": "aaa3e305-58ec-402c-e73e-d3cb9a65592e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de2ae17f819346f19cecc658f2309f19",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Queries:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Processing Time: 0.51 minutes\n"
          ]
        }
      ],
      "source": [
        "retrieval_results = execute_evaluation(golden_dataset, \n",
        "                                       class_name,\n",
        "                                       client,\n",
        "                                       reranker,\n",
        "                                       alpha=0.5,\n",
        "                                       retrieve_limit=100,\n",
        "                                       top_k=5,\n",
        "                                       search_type=\"hybrid\",\n",
        "                                       include_miss_info=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "xZM_fljy7AkP"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'n'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'Retriever'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'models/finetuned-all-MiniLM-L6-v2-300'</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'chunk_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'kw_hit_rate'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.72</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'kw_mrr'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.59</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'vector_hit_rate'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.52</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'vector_mrr'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.39</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'total_misses'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'total_questions'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'maxConnections'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'efConstruction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'ef'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>\n",
              "<span style=\"font-weight: bold\">}</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m{\u001b[0m\n",
              "    \u001b[32m'n'\u001b[0m: \u001b[1;36m5\u001b[0m,\n",
              "    \u001b[32m'Retriever'\u001b[0m: \u001b[32m'models/finetuned-all-MiniLM-L6-v2-300'\u001b[0m,\n",
              "    \u001b[32m'chunk_size'\u001b[0m: \u001b[1;36m256\u001b[0m,\n",
              "    \u001b[32m'kw_hit_rate'\u001b[0m: \u001b[1;36m0.72\u001b[0m,\n",
              "    \u001b[32m'kw_mrr'\u001b[0m: \u001b[1;36m0.59\u001b[0m,\n",
              "    \u001b[32m'vector_hit_rate'\u001b[0m: \u001b[1;36m0.52\u001b[0m,\n",
              "    \u001b[32m'vector_mrr'\u001b[0m: \u001b[1;36m0.39\u001b[0m,\n",
              "    \u001b[32m'total_misses'\u001b[0m: \u001b[1;36m21\u001b[0m,\n",
              "    \u001b[32m'total_questions'\u001b[0m: \u001b[1;36m100\u001b[0m,\n",
              "    \u001b[32m'maxConnections'\u001b[0m: \u001b[1;36m32\u001b[0m,\n",
              "    \u001b[32m'efConstruction'\u001b[0m: \u001b[1;36m128\u001b[0m,\n",
              "    \u001b[32m'ef'\u001b[0m: \u001b[1;36m64\u001b[0m\n",
              "\u001b[1m}\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Print the results of the evaluation\n",
        "print(retrieval_results)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1ced981f815d4a9eb2d857e44c52e8c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "4554a9e328e84c0d89359b9502e3fa59": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "654cee51ae9140b49354a8291121ae07": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68f90ea90b534654bec4ecf070f182c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "704c6a1f4bdd4a60910759426f71079a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f201c57fc5c146b880bcc69171df952d",
              "IPY_MODEL_70675964a5694565ba01449a833dc473",
              "IPY_MODEL_c6aba13165be44d0ad7335cf8a3bfad0"
            ],
            "layout": "IPY_MODEL_d30eea6ca492480aadf758cacd5b6044",
            "tabbable": null,
            "tooltip": null
          }
        },
        "70675964a5694565ba01449a833dc473": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_8c6f7af301cb4d1c9fd3b2dc46004400",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_68f90ea90b534654bec4ecf070f182c4",
            "tabbable": null,
            "tooltip": null,
            "value": 100
          }
        },
        "8c6f7af301cb4d1c9fd3b2dc46004400": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab2f1ee772954d7e8ce7e7e5bcf1af7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "c6aba13165be44d0ad7335cf8a3bfad0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_4554a9e328e84c0d89359b9502e3fa59",
            "placeholder": "​",
            "style": "IPY_MODEL_1ced981f815d4a9eb2d857e44c52e8c1",
            "tabbable": null,
            "tooltip": null,
            "value": " 100/100 [00:55&lt;00:00,  1.82it/s]"
          }
        },
        "d30eea6ca492480aadf758cacd5b6044": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f201c57fc5c146b880bcc69171df952d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_654cee51ae9140b49354a8291121ae07",
            "placeholder": "​",
            "style": "IPY_MODEL_ab2f1ee772954d7e8ce7e7e5bcf1af7f",
            "tabbable": null,
            "tooltip": null,
            "value": "Queries: 100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
